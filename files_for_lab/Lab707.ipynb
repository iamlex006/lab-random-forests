{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3fc380",
   "metadata": {},
   "source": [
    "# Lab 1: Let's build a forest! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af14a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90569\n",
       "1     4843\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "numerical = pd.read_csv('numerical.csv')\n",
    "categorical = pd.read_csv('categorical.csv')\n",
    "targets = pd.read_csv('target.csv')\n",
    "data = pd.concat([numerical, categorical, targets], axis = 1)\n",
    "data['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d5cbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abaf749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No NaNs! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d3af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we split and encode our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddfbd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/ppplmryx5_d7mfrd5d6968kr0000gn/T/ipykernel_71349/393626257.py:5: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  categoricalX = X.select_dtypes(np.object)\n"
     ]
    }
   ],
   "source": [
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "numericalX = X.select_dtypes(np.number)\n",
    "categoricalX = X.select_dtypes(np.object)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first').fit(categoricalX)\n",
    "encoded_categorical = encoder.transform(categoricalX).toarray()\n",
    "encoded_categorical = pd.DataFrame(encoded_categorical)\n",
    "X = pd.concat([numericalX, encoded_categorical], axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76ca90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72486, 356)\n",
      "(144972, 355)\n"
     ]
    }
   ],
   "source": [
    "trainset = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "category_0 = trainset[trainset['TARGET_B']==0]\n",
    "print(category_0.shape)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "cat_1 = trainset[trainset['TARGET_B']== 1 ]\n",
    "category_1 = resample(cat_1, replace = True, n_samples = len(category_0))\n",
    "trainset_new = pd.concat([category_0, category_1], axis = 0)\n",
    "trainset_new = trainset_new.sample(frac =1)\n",
    "X_train = trainset_new.drop(['TARGET_B'], axis=1)\n",
    "y_train = trainset_new['TARGET_B']\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19db739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have an upsampled dataset so we can model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242924b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']\n",
    "\n",
    "X_train = X_train.drop(['TARGET_D'], axis = 1)\n",
    "X_test = X_test.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd95200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6201818282151036\n",
      "0.6070324372478122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18083\n",
       "1     1000\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[11039,  7044],\n",
       "       [  455,   545]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.8,\n",
    "                             random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b04add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsampling the data gives us a slightly better result than the downsampling done in class, but the margin is very small\n",
    "#Given the instability of \"Tree based\" models (even forests), I wouldn't use a difference of 0.02 to make a final decision on which way is better\n",
    "#We need cross validation to get a more robust result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c05b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616643286270606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lex/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "print(np.mean(cross_val_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52a54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation result of downsampling was 0.58, we now have 0.62. It is a small margin, but I would recommend to go with upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a6ff3",
   "metadata": {},
   "source": [
    "# Lab 2: Final regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7cec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's model the amount donated from the existing data, but first we need to scale it and do some feature selection! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fccb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use a lot of the \"splitting\" work already done. \n",
    "#y is already created for the regression. \n",
    "#For X we just need to drop Target_B as it matches our target too closely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8d6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data[data['TARGET_D']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b86047",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_reg['TARGET_D']\n",
    "X = data_reg.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ceca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebcf93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# numerical_scaled = scaler.fit_transform(numericalX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888860f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(numerical_scaled).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a7dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold \n",
    "# var_threshold = 0.02\n",
    "# sel = VarianceThreshold(threshold=(var_threshold))\n",
    "\n",
    "# sel = sel.fit(numerical_scaled)\n",
    "# temp = sel.transform(numerical_scaled)\n",
    "# temp = pd.DataFrame(temp)\n",
    "# print(numerical_scaled.shape)\n",
    "# print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974c0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel.variances_ > var_threshold\n",
    "# sel.get_support()\n",
    "# var_list = list(sel.get_support())\n",
    "# list(zip(numerical.columns, var_list))\n",
    "# [col[0] for col in zip(numerical.columns, var_list) if col[1] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41623660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting an output of the columns with low variance so I can chose to keep them or not. \n",
    "#Will keep IC1, AGE, MAXRAMNT,AVGGIFT,LASTGIFT,NGIFTALL as significant data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf49be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3789b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b9c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5a509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc416b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be2260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccb966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b5076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f950b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45149f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
